<application>
  <component name="Translation.Cache">
    <option name="lastTrimTime" value="1695205382186" />
  </component>
  <component name="Translation.Settings">
    <option name="primaryLanguage" value="CHINESE" />
  </component>
  <component name="Translation.States">
    <option name="newTranslationDialogWidth" value="598" />
    <option name="newTranslationDialogX" value="2754" />
    <option name="newTranslationDialogY" value="476" />
    <option name="pinTranslationDialog" value="true" />
    <histories>
      <item value="Calculate the radius of the circle using Pythagoras. We know that any point on the circle is a point on the sphere. Thus we can construct a triangle with the sphere center, circle center, and a point on the circle. We then want to find its distance to the circle center, as that will be equal to the radius. As the point is on the sphere, it must be `sphereRadius` from the sphere center, forming the hypotenuse. The other side is between the sphere and circle centers, which we've already calculated to be `distanceToPlane`." />
      <item value="Now that we have the circle, we can find the horizon points. Since we've parametrized the plane, we can just do this in 2D." />
      <item value="Any of these conditions will yield NaN due to negative square roots. They are signs that clipping is needed, so we fallback on the already calculated values in that case." />
      <item value="Calculate tile plane ranges for sphere" />
      <item value="cone Height Sq" />
      <item value="scale it so that it is on the near plane instead." />
      <item value="Near-plane clipping - will get overwritten if no clipping is needed. `y` is given for the view plane (Z=1), scale it so that it is on the near plane instead." />
      <item value="Note: The y-plane is the plane that is determined by `y` in that it contains the vector (1, 0, 0) and goes through the points (0, y, 1) and (0, 0, 0). This would become a straight line in screen-space, and so it represents the boundary between two rows of tiles." />
      <item value="horizon points" />
      <item value="Project light sphere onto YZ plane, find the horizon points, and re-construct view space position of found points" />
      <item value="Assumes a point on the sphere, i.e. at distance `range` from the light position. If spot light, we check the angle between the direction vector from the light position and the light direction vector. Note that division by range is to normalize the vector, as we know that the resulting vector will have length `range`." />
      <item value="Finds the two horizon points seen from (0, 0) of a sphere projected onto either XZ or YZ. Takes clipping into account." />
      <item value="and re-construct view space position of found points." />
      <item value="lies both on the sphere and the near plan" />
      <item value="Thus the hypotenuse is formed by (a) and (c) with length `range`, and the known side is formed" />
      <item value="a point on the near plane at a distance `range` from the light position" />
      <item value="Radius of circle formed by intersection of sphere and near plane. Found using Pythagoras with a right triangle formed by three points: (a) light position (b) light position projected to near plane (c) a point on the near plane at a distance `range` from the light position (i.e. lies both on the sphere and the near plane) Thus the hypotenuse is formed by (a) and (c) with length `range`, and the known side is formed by (a) and (b) with length equal to the distance between the near plane and the light position. The remaining unknown side is formed by (b) and (c) with length equal to the radius of the circle. m_ClipCircleRadius = sqrt(sq(light.range) - sq(m_Near - m_LightPosition.z));" />
      <item value="Expands the tile Y range and the X range in the row containing the position." />
      <item value="false sharing" />
      <item value="respecting the asymmetric FOV (if it is used)" />
      <item value="Regarding itemOffset: minMaxZs contains [lights view 0, lights view 1, probes view 0, probes view 1] when using XR single pass instanced, and otherwise [lights, probes]. So we figure out what the offset is based on the view count and index." />
      <item value="m Directional Light Count" />
      <item value="1" />
      <item value="Fast Shadow Receiver Projector XXXXX" />
      <item value="Distribution" />
      <item value="onece" />
      <item value="stride" />
      <item value="deferred pass (&quot;camera color&quot; + &quot;camera depth&quot;), the implicit depth surface of &quot;camera color&quot; is used instead of &quot;camera depth&quot;, because BuiltinRenderTextureType.CameraTarget for depth means there is no explicit depth attachm" />
      <item value="around a bug where during gbuffer pass (MRT pass), the camera depth attachment is correctly bound, but during deferred pass (&quot;camera color&quot; + &quot;camera depth&quot;), the implicit depth surface of &quot;camera color&quot; is used instead of &quot;camera depth&quot;, because BuiltinRenderTextureType.CameraTarget for depth means there is no explicit depth attachment..." />
      <item value="If URP is NOT rendering to RT neither rendering with OpenGL: - Source Depth is NOT fliped. We CANNOT flip when copying depth and don't flip when sampling. (ProjectionParams.x == 1)" />
      <item value="- Source Depth is upside down. We need to copy depth by using a shader that has flipped matrix as well so we have same orientaiton for source and copy depth. - This also guarantess to be standard across if we are using a depth prepass. - When shaders (including shader graph) render objects that sample depth they adjust uv sign with _ProjectionParams.x. (https:docs.unity3d.comManualSL-PlatformDifferences.html) - All good." />
      <item value="If URP is NOT rendering to RT neither rendering with OpenGL:" />
      <item value="But if we only require it for post processing or the scene camera then we do it after rendering transparent objects Aim to have the most optimized render pass event for Depth Copy" />
      <item value="The aim is to minimize the number of render passes" />
      <item value="GLES can not use render texture's depth buffer with the color buffer of the backbuffer" />
      <item value="If camera requires depth and there's no depth pre-pass we create a depth texture that can be read later by effect requiring it. When deferred renderer is enabled, we must always create a depth texture and CANNOT use BuiltinRenderTextureType.CameraTarget. This is to get around a bug where during gbuffer pass (MRT pass), the camera depth attachment is correctly bound, but during deferred pass (&quot;camera color&quot; + &quot;camera depth&quot;), the implicit depth surface of &quot;camera color&quot; is used instead of &quot;camera depth&quot;, because BuiltinRenderTextureType.CameraTarget for depth means there is no explicit depth attachment..." />
      <item value="deferred pass (&quot;camera color&quot; + &quot;camera depth&quot;), the implicit depth surface of &quot;camera color&quot; is used instead of &quot;camera depth&quot;, because BuiltinRenderTextureType.CameraTarget for depth means there is no explicit depth attachment..." />
      <item value="When deferred renderer is enabled, we must always create a depth texture and CANNOT use BuiltinRenderTextureType.CameraTarget. This is to get around a bug where during gbuffer pass (MRT pass), the camera depth attachment is correctly bound, but during deferred pass (&quot;camera color&quot; + &quot;camera depth&quot;), the implicit depth surface of &quot;camera color&quot; is used instead of &quot;camera depth&quot;, because BuiltinRenderTextureType.CameraTarget for depth means there is no explicit depth attachment..." />
      <item value="When post-processing is enabled we can use the stack to resolve rendering to camera target (screen or RT). However when there are render passes executing after post we avoid resolving to screen so rendering continues (before sRGBConvertion etc)" />
      <item value="berPost can only handle upscaling with linear filtering. All other filtering methods require the FinalPost pass." />
      <item value="FXAA expects to be the last shader running on the image before it's presented to the screen. Since users are allowed to add additional render passes after post processing occurs, we can't run FXAA until all of those passes complete as well. The FinalPost pass is guaranteed to execute after user authored passes so FXAA is always run inside of it." />
      <item value="Optimized store actions are very important on tile based GPUs and have a great impact on performance. if MSAA is enabled and any of the following passes need a copy of the color or depth target, make sure the MSAA'd surface is stored" />
      <item value="Optimized store actions are very important on tile based GPUs and have a great impact on performance. if MSAA is enabled and any of the following passes need a copy of the color or depth target, make sure the MSAA'd surface is stored if following passes won't use it then just resolve (the Resolve action will still store the resolved surface, but discard the MSAA'd surface, which is very expensive to store)." />
      <item value="Depth priming requires a manual resolve of MSAA depth right after the depth prepass. If autoresolve is supported but MSAA is 1x then a copy is still required." />
      <item value="In deferred mode, depth-normal prepass does really primes the depth and normal buffers, instead of creating a copy. It is necessary because we need to render depth&amp;normal for forward-only geometry and it is the only way to get them before the SSAO pass." />
      <item value="Doesn't create texture for Overlay cameras as they are already overlaying on top of created textures." />
      <item value="Scene filtering redraws the objects on top of the resulting frame. It has to draw directly to the sceneview buffer." />
      <item value="Temporarily disable depth priming on certain platforms such as Vulkan because we lack proper depth resolve support." />
      <item value="Currently in non-MRT case, color attachment can actually be a depth attachment" />
      <item value="Toolbar overlays must inherit `ToolbarOverlay` and implement a parameter-less constructor. The contents of a toolbar are populated with string IDs, which are passed to the base constructor. IDs are defined by EditorToolbarElementAttribute." />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="136" />
        <entry key="ENGLISH" value="137" />
        <entry key="GERMAN" value="1" />
      </map>
    </option>
  </component>
</application>